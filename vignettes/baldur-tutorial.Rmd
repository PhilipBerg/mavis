---
title: "Baldur-Tutorial"
output: rmarkdown::html_vignette
author: "Philip Berg"
vignette: >
  %\VignetteIndexEntry{baldur-tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = T
)
```
# 1. Setup
First we load `mavis` and then we use the `yeast_prog` dataset and to perform normalization and imputation. In addition, we will setup the model dependent variables we need.
```{r, setup}
library(mavis)
# Setup design matrix
yeast_design <- model.matrix(~ 0 + factor(rep(1:2, each = 3)))
colnames(yeast_design) <- paste0("ng", c(50, 100))

# Normalize data
yeast <- yeast_prog %>% 
  psrn('identifier')

# Compare the first and second column of the design matrix
# with the following contrast matrix
yeast_contrast <- matrix(1:2, nrow = 1)
```
Importantly, note that the column names of the design matrix are unique subsets of the names of the columns within the conditions:
```{r design}
colnames(yeast)
colnames(yeast_design)
```
This is essential for `mavis` to know which columns to use in calculations and to perform transformations on.

# 2. Mixture separation, prior estimation, and uncertainty estimation
The first step is to add the mean-variance trends to our data matrix:
```{r, mv}
yeast <- yeast %>% 
  calculate_mean_sd_trends(yeast_design)
```
Next is to infer the mixture of the data:
```{r cluster}
yeast_cluster <- yeast %>% 
  trend_partitioning(design_matrix = yeast_design)
```
Then we fit the gamma regression:
```{r, glm}
gam_reg <- yeast_cluster %>% 
  fit_gamma_regression()
```
Next we perform imputation:
```{r, imp}
yeast_cluster_imp <- yeast_cluster %>% 
  single_imputation(yeast_design, gam_reg)
```
After imputation we re-estimate the mean-variance trends and re-fit the gamma model:
```{r, reeset}
yeast_cluster_imp <- yeast_cluster_imp %>% 
  calculate_mean_sd_trends(yeast_design)
gam_reg_imp <- yeast_cluster_imp %>% 
  fit_gamma_regression()
```
Finally, we estimate the parameters needed for `baldur`:
```{r,priors}
# Estimate gamma priors
yeast_cluster_imp <- yeast_cluster_imp %>% 
  estimate_gamma_priors(design_matrix = yeast_design, gam_reg_imp)
# Get each data points uncertainty
yeast_unc <- yeast_cluster_imp %>% 
  estimate_uncertainty('identifier', design_matrix = yeast_design, gam_reg_imp)
```
# 3. Run the sampling procedure
Side note: I highly recommend running `baldur` with the parallel implementation in next section due to the massive speed up.
Finally we sample the posterior of each row in the data as follows:
```{r, posterior}
yeast_results <- yeast_cluster_imp %>% 
  # For time purposes we only sample for six rows
  head() %>% 
  sample_posterior(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc
  )
# The top hits then looks as follows:
yeast_results %>% 
  dplyr::arrange(err)
```
Here `err` is the probability of error, i.e., the tail-density supporting the null-hypothesis, `lfc` is the estimated log$_2$-fold change, and `sigma` is the common variance.
Columns without suffix shows the mean estimate from the posterior, while the suffixes `_025`, `_975`, and `_med` are the 2.5, 97.5, and 50.0 percentiles, respectively.
The suffixes `_eff` and `_rhat` and the prefix `lp__` are the diagnostic variables returned by `rstan` (please see the Stan manual for details).

# 4. Sampling with parallel computation
As of now, Rstan models compiled with a package cannot be ran in parallel using the `multidplyr` backend.
Therefore, we first need to compile the model, and then we can use the compiled model to run parallel computation:
```{r parellel}
model <- compile_model()
yeast_results <- yeast_cluster_imp %>% 
  # For time purposes we only sample for 20 rows
  head(20) %>% 
  sample_posterior(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc,
    model,
    2
  )
```
