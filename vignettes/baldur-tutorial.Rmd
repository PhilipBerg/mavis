---
title: "Baldur-Tutorial"
output: rmarkdown::html_vignette
author: "Philip Berg"
vignette: >
  %\VignetteIndexEntry{Baldur-Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# 1. Setup
First we load `mavis` and then we use the `yeast` dataset and to perform normalization and imputation. In addition, we will setup the model dependent variables we need.

```r
library(mavis)
# Setup design matrix
yeast_design <- model.matrix(~ 0 + factor(rep(1:2, each = 3)))
colnames(yeast_design) <- paste0("ng", c(50, 100))

# Normalize data
yeast <- yeast %>%
  psrn('identifier')

# Compare the first and second column of the design matrix
# with the following contrast matrix
yeast_contrast <- matrix(c(-1, 1), ncol = 1)
```
Importantly, note that the column names of the design matrix are unique subsets of the names of the columns within the conditions:

```r
colnames(yeast)
#> [1] "identifier" "ng50_1"     "ng50_2"     "ng50_3"     "ng100_1"    "ng100_2"    "ng100_3"
colnames(yeast_design)
#> [1] "ng50"  "ng100"
```
This is essential for `mavis` to know which columns to use in calculations and to perform transformations on.

Sidenote: other datasets can be downloaded from figshare (link will be added on publication).

# 2. Mixture separation, prior estimation, and uncertainty estimation
The first step is to add the mean-variance trends to our data matrix:

```r
yeast <- yeast %>%
  calculate_mean_sd_trends(yeast_design)
```
Next we perform imputation:

```r
yeast_imp <- yeast %>%
  single_imputation(yeast_design)
#> Estimating Imputation Paramters
#> Previous error: Inf 	>	Current error: 5.793245 
#> Iteration time:
#>  5.999608 secs 
#> 
#> Previous error: 5.793245 	>	Current error: 0.1237535 
#> Iteration time:
#>  6.101243 secs 
#> 
#> Previous error: 0.1237535 	>	Current error: 0.05545268 
#> Iteration time:
#>  6.100341 secs 
#> 
#> Previous error: 0.05545268 	>	Current error: 0.02644271 
#> Iteration time:
#>  6.11713 secs 
#> 
#> Previous error: 0.02644271 	>	Current error: 0.0167691 
#> Iteration time:
#>  6.096946 secs 
#> 
#> Previous error: 0.0167691 	>	Current error: 0.008999636 
#> Iteration time:
#>  6.102479 secs 
#> 
#> Previous error: 0.008999636 	>	Current error: 0.007909314 
#> Iteration time:
#>  6.101781 secs 
#> 
#> Previous error: 0.007909314 	<	Current error: 0.008314841 	Breaking 
#> Iteration time:
#>  6.111201 secs
```
After imputation we re-estimate the mean-variance trends and partition the data:

```r
yeast_grid <- yeast_imp %>%
  calculate_mean_sd_trends(yeast_design) %>%
  grid_search(yeast_design, n_h1 = 20, n_h2 = 20, workers = round(parallel::detectCores()/2))
```

![plot of chunk reeset](reeset-1.png)

```r
yeast_grid
#> # A tibble: 400 × 5
#>         h1      h2 formula       s clustered_data       
#>      <dbl>   <dbl> <list>    <dbl> <list>               
#>  1 0.0875  0.250   <formula>  285. <tibble [2,235 × 11]>
#>  2 0.0875  0.331   <formula>  266. <tibble [2,235 × 11]>
#>  3 0.0875  0.413   <formula>  249. <tibble [2,235 × 11]>
#>  4 0.00620 0.331   <formula>  221. <tibble [2,235 × 11]>
#>  5 0.169   0.331   <formula>  208. <tibble [2,235 × 11]>
#>  6 0.00620 0.250   <formula>  203. <tibble [2,235 × 11]>
#>  7 0.00620 0.413   <formula>  193. <tibble [2,235 × 11]>
#>  8 0.00620 0.00620 <formula>  190. <tibble [2,235 × 11]>
#>  9 0.00620 0.0875  <formula>  190. <tibble [2,235 × 11]>
#> 10 0.00620 0.169   <formula>  189. <tibble [2,235 × 11]>
#> # ℹ 390 more rows
# Select the dataset with the largest score
yeast_cluster <- yeast_grid$clustered_data[[1]]
```
Then we fit the gamma regression model:

```r
gam_clust_reg <- yeast_cluster %>%
  fit_gamma_regression(sd ~ mean + c)
```
Finally, we estimate the uncertainties needed for `baldur`:

```r
# Get each data points uncertainty
yeast_unc <- yeast_cluster %>%
  estimate_uncertainty('identifier', design_matrix = yeast_design, gam_clust_reg)
```
# 3. Run the sampling procedure
Side note: I highly recommend running `baldur` with the parallel implementation in next section due to the massive speed up.
Finally we sample the posterior of each row in the data as follows:

```r
yeast_results <- gam_clust_reg %>%
  # Estimate gamma priors
  estimate_gamma_hyperparameters(yeast_cluster, design_matrix = yeast_design) %>%
  # For time purposes we only sample for six rows
  head() %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc
  )
# The top hits then looks as follows:
yeast_results %>%
  dplyr::arrange(err)
#> # A tibble: 6 × 22
#>   identifier                              comparison       err     lfc lfc_025   lfc_50 lfc_975 lfc_eff lfc_rhat sigma sigma_025 sigma_50 sigma_975 sigma_eff sigma_rhat     lp lp_025  lp_50 lp_975 lp_eff lp_rhat warnings 
#>   <chr>                                   <chr>          <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl>    <dbl> <dbl>     <dbl>    <dbl>     <dbl>     <dbl>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <list>   
#> 1 Cre01.g004500.t1.2|PACid:30789545|--355 ng100 vs ng50 0.0874 -0.275   -0.603 -0.268    0.0391   4547.    1.00  0.162    0.119     0.160     0.221     4159.      1.00   -5.07 -10.2   -4.72  -1.88  1696.    1.00 <chr [0]>
#> 2 Cre01.g000800.t1.2|PACid:30788536|--66  ng100 vs ng50 0.0995 -0.239   -0.518 -0.239    0.0551   4692.    1.00  0.141    0.0911    0.137     0.218     2184.      1.00    3.43  -2.22   3.79   6.94  1253.    1.00 <chr [0]>
#> 3 Cre01.g004500.t1.2|PACid:30789545|--444 ng100 vs ng50 0.288  -0.266   -0.762 -0.268    0.220    6253.    1.00  0.245    0.190     0.242     0.311     4675.      1.00  -17.1  -22.2  -16.8  -14.1   1759.    1.00 <chr [0]>
#> 4 Cre01.g002300.t1.2|PACid:30788660|--40  ng100 vs ng50 0.384   0.298   -0.375  0.298    0.965    6522.    0.999 0.338    0.269     0.335     0.423     5665.      1.00  -23.6  -28.1  -23.3  -20.7   1755.    1.00 <chr [0]>
#> 5 Cre01.g002300.t1.2|PACid:30788660|--168 ng100 vs ng50 0.725   0.172   -0.768  0.176    1.11     5264.    1.00  0.467    0.362     0.462     0.600     4568.      0.999 -21.6  -26.9  -21.2  -18.5   1730.    1.00 <chr [0]>
#> 6 Cre01.g004350.t1.2|PACid:30788641|--148 ng100 vs ng50 0.971   0.0186  -1.02   0.00632  1.03     5424.    1.00  0.493    0.387     0.488     0.627     4035.      1.00  -24.3  -29.2  -23.9  -21.2   1701.    1.00 <chr [0]>
```
Here `err` is the probability of error, i.e., the tail-density supporting the null-hypothesis, `lfc` is the estimated log$_2$-fold change, and `sigma` is the common variance.
Columns without suffix shows the mean estimate from the posterior, while the suffixes `_025`, `_975`, and `_med` are the 2.5, 97.5, and 50.0 percentiles, respectively.
The suffixes `_eff` and `_rhat` and the prefix `lp__` are the diagnostic variables returned by `rstan` (please see the Stan manual for details).

# 4. Sampling with parallel computation
As of now, Rstan models compiled with a package cannot be ran in parallel using the `multidplyr` backend.
Therefore, we first need to compile the model, and then we can use the compiled model to run parallel computation:

```r
yeast_results <- gam_clust_reg %>%
  # Estimate gamma priors
  estimate_gamma_hyperparameters(yeast_cluster, design_matrix = yeast_design) %>%
  # For time purposes we only sample for 20 rows
  head(20) %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc,
    clusters =  2
  )
```
