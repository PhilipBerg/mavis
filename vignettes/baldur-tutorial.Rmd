---
title: "Baldur-Tutorial"
output: rmarkdown::html_vignette
author: "Philip Berg"
vignette: >
  %\VignetteIndexEntry{Baldur-Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# 1. Setup
First we load `mavis` and then we use the `yeast` dataset and to perform normalization and imputation. In addition, we will setup the model dependent variables we need.

```r
library(mavis)
# Setup design matrix
yeast_design <- model.matrix(~ 0 + factor(rep(1:2, each = 3)))
colnames(yeast_design) <- paste0("ng", c(50, 100))

# Normalize data
yeast <- yeast %>%
  psrn('identifier')

# Compare the first and second column of the design matrix
# with the following contrast matrix
yeast_contrast <- matrix(c(-1, 1), ncol = 1)
```
Importantly, note that the column names of the design matrix are unique subsets of the names of the columns within the conditions:

```r
colnames(yeast)
#> [1] "identifier" "ng50_1"     "ng50_2"     "ng50_3"     "ng100_1"    "ng100_2"    "ng100_3"
colnames(yeast_design)
#> [1] "ng50"  "ng100"
```
This is essential for `mavis` to know which columns to use in calculations and to perform transformations on.

Sidenote: other datasets can be downloaded from figshare (link will be added on publication).

# 2. Mixture separation, prior estimation, and uncertainty estimation
The first step is to add the mean-variance trends to our data matrix:

```r
yeast <- yeast %>%
  calculate_mean_sd_trends(yeast_design)
```
Next we perform imputation:

```r
yeast_imp <- yeast %>%
  single_imputation(yeast_design)
#> Estimating Imputation Paramters
#> Previous error: Inf 	>	Current error: 5.918522 
#> Iteration time:
#>  6.063852 secs 
#> 
#> Previous error: 5.918522 	>	Current error: 0.1268151 
#> Iteration time:
#>  5.314738 secs 
#> 
#> Previous error: 0.1268151 	>	Current error: 0.06087916 
#> Iteration time:
#>  5.103424 secs 
#> 
#> Previous error: 0.06087916 	>	Current error: 0.03199564 
#> Iteration time:
#>  5.330427 secs 
#> 
#> Previous error: 0.03199564 	>	Current error: 0.0150328 
#> Iteration time:
#>  6.762667 secs 
#> 
#> Previous error: 0.0150328 	>	Current error: 0.01131249 
#> Iteration time:
#>  7.034297 secs 
#> 
#> Previous error: 0.01131249 	>	Current error: 0.008185775 
#> Iteration time:
#>  7.211469 secs 
#> 
#> Previous error: 0.008185775 	<	Current error: 0.009011511 	Breaking 
#> Iteration time:
#>  7.180205 secs
```
After imputation we re-estimate the mean-variance trends and partition the data:

```r
yeast_grid <- yeast_imp %>%
  calculate_mean_sd_trends(yeast_design) %>%
  grid_search(yeast_design, n_h1 = 20, n_h2 = 20, workers = round(parallel::detectCores()/2))
```

![plot of chunk reeset](reeset-1.png)

```r
yeast_grid
#> # A tibble: 400 × 5
#>         h1      h2 formula       s clustered_data       
#>      <dbl>   <dbl> <list>    <dbl> <list>               
#>  1 0.0875  0.250   <formula>  280. <tibble [2,235 × 11]>
#>  2 0.0875  0.331   <formula>  262. <tibble [2,235 × 11]>
#>  3 0.0875  0.169   <formula>  252. <tibble [2,235 × 11]>
#>  4 0.00620 0.331   <formula>  220. <tibble [2,235 × 11]>
#>  5 0.169   0.331   <formula>  215. <tibble [2,235 × 11]>
#>  6 0.0875  0.413   <formula>  211. <tibble [2,235 × 11]>
#>  7 0.00620 0.250   <formula>  208. <tibble [2,235 × 11]>
#>  8 0.00620 0.413   <formula>  198. <tibble [2,235 × 11]>
#>  9 0.00620 0.00620 <formula>  188. <tibble [2,235 × 11]>
#> 10 0.00620 0.0875  <formula>  188. <tibble [2,235 × 11]>
#> # ℹ 390 more rows
# Select the dataset with the largest score
yeast_cluster <- yeast_grid$clustered_data[[1]]
```
Then we fit the gamma regression model:

```r
gam_clust_reg <- yeast_cluster %>%
  fit_gamma_regression(sd ~ mean + c)
```
Finally, we estimate the uncertainties needed for `baldur`:

```r
# Get each data points uncertainty
yeast_unc <- yeast_cluster %>%
  estimate_uncertainty('identifier', design_matrix = yeast_design, gam_clust_reg)
```
# 3. Run the sampling procedure
Side note: I highly recommend running `baldur` with the parallel implementation in next section due to the massive speed up.
Finally we sample the posterior of each row in the data as follows:

```r
yeast_results <- gam_clust_reg %>%
  # Estimate gamma priors
  estimate_gamma_hyperparameters(yeast_cluster, design_matrix = yeast_design) %>%
  # For time purposes we only sample for six rows
  head() %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc
  )
# The top hits then looks as follows:
yeast_results %>%
  dplyr::arrange(err)
#> # A tibble: 6 × 22
#>   identifier  comparison    err     lfc lfc_025   lfc_50 lfc_975 lfc_eff lfc_rhat sigma sigma_025 sigma_50 sigma_975 sigma_eff sigma_rhat     lp
#>   <chr>       <chr>       <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl>    <dbl> <dbl>     <dbl>    <dbl>     <dbl>     <dbl>      <dbl>  <dbl>
#> 1 Cre01.g004… ng100 vs … 0.0894 -0.278   -0.606 -0.276    0.0354   6657.    1.00  0.163    0.118     0.160     0.223     4610.      0.999  -4.88
#> 2 Cre01.g000… ng100 vs … 0.0999 -0.241   -0.535 -0.243    0.0457   5192.    1.00  0.140    0.0898    0.136     0.217     2690.      1.00    3.66
#> 3 Cre01.g004… ng100 vs … 0.296  -0.264   -0.772 -0.261    0.251    5814.    0.999 0.245    0.192     0.242     0.313     4419.      1.00  -16.9 
#> 4 Cre01.g002… ng100 vs … 0.414   0.287   -0.415  0.288    0.984    5219.    1.00  0.341    0.270     0.336     0.432     5241.      1.00  -23.6 
#> 5 Cre01.g002… ng100 vs … 0.759   0.153   -0.835  0.156    1.13     5902.    1.00  0.471    0.365     0.466     0.606     4350.      1.00  -21.8 
#> 6 Cre01.g004… ng100 vs … 0.982   0.0110  -0.946  0.00221  0.998    5928.    1.00  0.492    0.388     0.487     0.626     5237.      1.00  -24.3 
#> # ℹ 6 more variables: lp_025 <dbl>, lp_50 <dbl>, lp_975 <dbl>, lp_eff <dbl>, lp_rhat <dbl>, warnings <list>
```
Here `err` is the probability of error, i.e., the tail-density supporting the null-hypothesis, `lfc` is the estimated log$_2$-fold change, and `sigma` is the common variance.
Columns without suffix shows the mean estimate from the posterior, while the suffixes `_025`, `_975`, and `_med` are the 2.5, 97.5, and 50.0 percentiles, respectively.
The suffixes `_eff` and `_rhat` and the prefix `lp__` are the diagnostic variables returned by `rstan` (please see the Stan manual for details).

# 4. Sampling with parallel computation
As of now, Rstan models compiled with a package cannot be ran in parallel using the `multidplyr` backend.
Therefore, we first need to compile the model, and then we can use the compiled model to run parallel computation:

```r
yeast_results <- gam_clust_reg %>%
  # Estimate gamma priors
  estimate_gamma_hyperparameters(yeast_cluster, design_matrix = yeast_design) %>%
  # For time purposes we only sample for 20 rows
  head(20) %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    yeast_unc,
    clusters =  2
  )
```
